---
title: "p8105_hw2_lah2231_new.Rmd"
output: github_document
date: "2024-09-29"
---

## Problem 1
```{r}
library(readr)
#install.packages("dplyr")
library(dplyr)
#install.packages("tidyr)
library(tidyr)


data <- read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv")

#View(data)

data_cleaned <- select(data, "Line", "Station Name", "Station Latitude", "Station Longitude", "Route1", "Route2", "Route3", "Route4", "Route5", "Route6", "Route7", "Route8", "Route9", "Route10", "Route11", "Entry", "Vending", "Entrance Type", "ADA")

#head(data_cleaned)

data_cleaned2 <- mutate(data_cleaned, Entry = ifelse(Entry == "YES", TRUE, FALSE))

head(data_cleaned2)

dim(data_cleaned2)

# It is a dataset about the New York Metro with information about the different stations, lines, routes, where the stations are located and what the different stations provide. Rows x columns is 1868 x 19.

distinct_stations <- distinct(data_cleaned2, `Station Name`, Line)
number_distinct_stations <- nrow(distinct_stations)
print(number_distinct_stations)

#There are 465 distinct stations

ADA_stations <- filter(data_cleaned2, ADA == TRUE)
#print(ADA_stations)
# There are 468 stations ADA compliant

data_cleaned3 <- mutate(data_cleaned2, Vending = ifelse(Vending == "YES", TRUE, FALSE))
No_vending <- filter(data_cleaned3, Vending == FALSE)
proportion_entry_no_vending <- mean(No_vending$Entry)
print(proportion_entry_no_vending)
# 30% of the stations have ADA and no vening


#Making route number and name distinct columns added
data_cleaned3 <- mutate(data_cleaned3, across(starts_with("Route"), as.character))

data_longer <- pivot_longer(data_cleaned3, 
                          cols = starts_with("Route"), 
                          names_to = "Route_Number", 
                          values_to = "Route_Name", 
                          values_drop_na = TRUE)

#stations that serve the A train
a_train_stations <- filter(data_longer, Route_Name == "A")
n_a_train_stations <- nrow(distinct(a_train_stations, `Station Name`, Line))
print(n_a_train_stations)

#a train stations that ara ADA compliat
ada_a_train_stations <- filter(a_train_stations, ADA == TRUE)
n_ada_a_train_stations <- nrow(distinct(ada_a_train_stations, `Station Name`, Line))
print(n_ada_a_train_stations)
```

## Problem 2 Mr. Trash Wheel
```{r}
#install.packages("readxl")
library(readxl)
#install.packages("dplyr")
library(dplyr)

#Mr. Trash Wheel
mr_trash_wheel_data <- read_excel("data/202409 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", skip = 1) |> slice(1:(n() - 2))

head(mr_trash_wheel_data)

# Rounding sports balls
mr_trash_wheel_data <- mr_trash_wheel_data |>
  mutate(`Sports Balls` = as.integer(round(`Sports Balls`)))

head(mr_trash_wheel_data)


#Professor Trash Wheel
prof_trash_wheel_data <- read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", skip = 1) |> slice(1:(n() - 3))


#Gwynnda Trash Wheel
gwynnda_trash_wheel_data <- read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", skip = 1) |> slice(1:(n() - 1))


# Converting Year column to character in all datasets
mr_trash_wheel_data <- mr_trash_wheel_data |> mutate(Year = as.character(Year))
prof_trash_wheel_data <- prof_trash_wheel_data |> mutate(Year = as.character(Year))
gwynnda_trash_wheel_data <- gwynnda_trash_wheel_data |> mutate(Year = as.character(Year))

#Which Trash Wheel Identifier Column added to each
mr_trash_wheel_data <- mr_trash_wheel_data |> mutate(Trash_Wheel = "Mr. Trash Wheel")
prof_trash_wheel_data <- prof_trash_wheel_data |> mutate(Trash_Wheel = "Professor Trash Wheel")
gwynnda_trash_wheel_data <- gwynnda_trash_wheel_data |> mutate(Trash_Wheel = "Gwynnda Trash Wheel")

#Three datasets to one with addiitonal identifier column 
combined_trash_data <- bind_rows(mr_trash_wheel_data, prof_trash_wheel_data, gwynnda_trash_wheel_data)

# Check the combined data
#View(combined_trash_data)
str(combined_trash_data)
```

```{r}
#Dataset exploration for paragraph

num_observations <- nrow(combined_trash_data)
column_names <- colnames(combined_trash_data)
print(num_observations)
print(column_names)

#Professor Trash Wheel totl weight
prof_trash_wheel_total_weight <- combined_trash_data |>
  filter(Trash_Wheel == "Professor Trash Wheel") |>
  summarize(total_weight = sum(`Weight (tons)`, na.rm = TRUE))
print(prof_trash_wheel_total_weight)


#cigarette butts collected by Gwynnda trash wheel June 2022
gwynnda_cigarettes_june22 <- combined_trash_data |>
  filter(Trash_Wheel == "Gwynnda Trash Wheel", format(Date, "%Y-%m") == "2022-06") |>
  summarize(total_cigarrette_butts = sum(`Cigarette Butts`, na.rm = TRUE))
print(gwynnda_cigarettes_june22)
```

This new combined dataset includes information about the three robots Mr. Trash Wheel, Professor Trash Wheel and Gwynnda Trash Wheel. It has `r num_observations`observations/rows. The columns have information about each robot's following characteristic: `r column_names `. Key variables regarding the trash collected are for example: `r column_names[5] `, `r column_names[6] ` and also information regarding which kind of trash was collected such as `r column_names[11] ` or `r column_names[12] `. The weight of trash collected by Prof. trash Wheel is: `r prof_trash_wheel_total_weight$total_weight`. In June 2022, Gwynnda Trash Wheel collected `r gwynnda_cigarettes_june22$total_cigarrette_butts` cigarette butts.


## Problem 3 Great British Bake Off
```{r}
bakers <- read_csv("data/bakers.csv")
bakes <- read_csv("data/bakes.csv")
results <- read_csv("data/results.csv", skip = 2)
viewers <- read_csv("data/viewers.csv")

head(bakers)
head(results)
head(bakes)
head(viewers)

#looking for unmatched bakers that are in bakes but not in bakers
unmatched_bakers <- anti_join(bakes, bakers, by = c("Baker" = "Baker Name"))
nrow(unmatched_bakers)

#looking for unmatched bakers that are in bakes but not in results
unmatched_bakers_results <- anti_join(bakes, results, by = c("Baker" = "baker"))
nrow(unmatched_bakers_results)
```
The number of unmatched bakers in bakes but not in bakers is `r nrow(unmatched_bakers)`. The number of unmatched bakers in bakes but not in results is `r nrow(unmatched_bakers_results)`.

#Merging
```{r}
# First merging "Baker Name" column from "bakers" dataset on "baker" in "bakes" dataset which only has first names and "Series"
bakers <- bakers |>
  mutate(First_Name = sub(" .*", "", `Baker Name`))

bakes_bakers <- bakes |>
  left_join(bakers, by = c("Baker" = "First_Name", "Series" = "Series"))

head(bakes_bakers)


#Second merge of series in results with Series in bakes_bakers, episode in results with Episode in bakes_bakers, baker in results with Baker in bakes_bakers
final_dataset <- bakes_bakers |>
  right_join(results, by = c("Series" = "series", "Episode" = "episode", "Baker" = "baker"))

head(final_dataset)
#View(final_dataset)
```

#Reorganizing
```{r}
#Reorgnaizing so important columns come first

final_dataset <- final_dataset |>
  select(1:6, technical, result, everything())

head(final_dataset)

write_csv(final_dataset, "data/final_dataset.csv")
```
Process description: After loading I inspected the datasets, I deleted unnecessary rows and checked for missing or unmatched entries using anti_join. To merge the datasets, I first extracted the first names from Baker Name in the bakers dataset to match the Baker column in the bakes dataset. I then merged bakes_bakers with results by matching on Series, Episode, and Baker. After some exploring and seeing that there is no series 9 and ten in bakers i did a right join. After reordering key variables which I found to be more impirtant than additional facts about the bakers. A question that remains for me is why there a re so many missing results, especially for the "technical" challenges. I exported the final cleaned dataset. This dataset includes all relevant information on bakers, their bakes and their performance across all episodes.

#Star Bakers
```{r}
# "STAR BAKER" or "WINNER" for seasons 5 - 10
star_bakers_winners <- final_dataset |>
  filter(Series >= 5 & Series <= 10 & (result == "STAR BAKER" | result == "WINNER")) |>
  select(Series, Episode, Baker, result) |>
  arrange(Series, Episode)

head(star_bakers_winners)
```


```{r}
predictable_bakers <- star_bakers_winners |>
  count(Baker, name = "star_baker_count") |>
  arrange(desc(star_baker_count))

predictable_bakers
```


In many cases the person that was star baker several times and especially towards the end ended up winning. It is not always the person with the most star baker awards though.

# viewers
```{r}
# Viewer dataset
viewers <- read_csv("data/viewers.csv")
head(viewers, 10)

#Counting the number of NA values
na_count <- colSums(is.na(viewers))
print(na_count)
# There are very few missing values so I will not delete those rows or columns.

# Average viewers for season 1
avg_viewership_season_1 <- mean(viewers$`Series 1`, na.rm = TRUE)
print(avg_viewership_season_1)

# Average viewers for season 5
avg_viewership_season_5 <- mean(viewers$`Series 5`, na.rm = TRUE)
print(avg_viewership_season_5)
```

The viewers dataset contains `r nrow(viewers)` rows. The number of missing values per column is `r na_count`. Because there are very few missing values I did not remove any rows or columns. The average viewership for Season 1 is `r avg_viewership_season_1`, and for Season 5 it is `r avg_viewership_season_5`.


